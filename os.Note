操作系统&多线程
=

1.进程状态转化图？
<img src="images/os_1.jpg" alt="jvm物理结构" />
就绪(Ready)状态：当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。
执行（Running）状态：当进程已获得处理机，其程序正在处理机上执行，此时的进程状态称为执行状态。
阻塞(Blocked)状态：正在执行的进程，由于等待某个事件发生而无法执行时，便放弃处理机而处于阻塞状态。引起进程阻塞的事件可以有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件(信号)等。


2.线程状态转化图？
<img src="images/os_2.jpg" alt="jvm物理结构" />
线程间的状态转换： 

1. 新建(new)：新创建了一个线程对象。

2. 可运行(runnable)：线程对象创建后，其他线程(如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。

3. 运行(running)：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。

4. 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 

(一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。

(二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。

(三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

5. 死亡(dead)：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。



3.sleep与wait的区别？
sleep来自Thread类，wait来自Object类
sleep方法没有释放锁，而wait方法释放了锁，sleep不出让系统资源；wait是进入线程等待池等待，出让系统资源，其他线程可以占用CPU。一般wait不会加时间限制，因为如果wait线程的运行资源不够，再出来也没用，要等待其他线程调用notify/notifyAll唤醒等待池中的所有线程，才会进入就绪队列等待OS分配系统资源。sleep(milliseconds)可以用时间指定使它自动唤醒过来，如果时间不到只能调用interrupt()强行打断。
wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

4.线程和进程的区别是什么？
进程可以认为是程序执行时的一个实例。进程是系统进行资源分配的独立实体， 且每个进程拥有独立的地址空间。一个进程无法直接访问另一个进程的变量和数据结构， 如果希望让一个进程访问另一个进程的资源，需要使用进程间通信，比如：管道，文件， 套接字等。

一个进程可以拥有多个线程，每个线程使用其所属进程的栈空间。 线程与进程的一个主要区别是，同一进程内的多个线程会共享部分状态， 多个线程可以读写同一块内存(一个进程无法直接访问另一进程的内存)。同时， 每个线程还拥有自己的寄存器和栈，其它线程可以读写这些栈内存。

线程是进程的一个特定执行路径。当一个线程修改了进程中的资源， 它的兄弟线程可以立即看到这种变化。

进程是系统进行资源分配的基本单位，有独立的内存地址空间； 线程是CPU调度的基本单位，没有单独地址空间，有独立的栈，局部变量，寄存器， 程序计数器等。

创建进程的开销大，包括创建虚拟地址空间等需要大量系统资源； 创建线程开销小，基本上只有一个内核对象和一个堆栈。

一个进程无法直接访问另一个进程的资源；同一进程内的多个线程共享进程的资源。

进程切换开销大，线程切换开销小；进程间通信开销大，线程间通信开销小。

线程属于进程，不能独立执行。每个进程至少要有一个线程，成为主线程


5.windows 内存管理的几种方式及其优缺点
页式管理:将各进程的虚拟空间划分为若干个长度相等的页；把内存空间按照页的大小划分成片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表；并用相应的硬件地址变换机构来解决离散地址变换问题。优点是没有外碎片，每个内碎片不超过页的大小，内存利用率高。缺点是无法反应程序逻辑结构，不利用共享。
段式管理:把程序按照内容或过程函数关系分段，以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。其优点是反应程序逻辑结构，利用共享。缺点是会产生碎片,内存利用率低。
段页式管理：为每个作业或进程建立一张段表。一个段又被划分成了若干个页。每个段必须建立一张页表以把段中的虚页变换成内存中的实际页面。具有两者的优点。复杂性和开销也就随之增加了。另外需要的硬件以及占用的内存也有所增加。使得速度降下来。

6.同步、异步
同步就是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么这个进程将会一直等待下去，直到收到返回信息才继续执行下去；异步是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。

7.编译的完整过程：C源程序(.c)－－>预编译处理(.i)－－>编译、优化程序（.s）－－>汇编程序(.o)－－>链接程序（.exe、.elf、.axf等）
预编译处理:读取c源程序，对其中的伪指令（以#开头的指令）和特殊符号进行处理
<img src="images/os_3.png" alt="jvm物理结构" />
编译:通过词法分析和语法分析，在确认所有的指令都符合语法规则之后，将其翻译成等价的中间代码表示或汇编代码。
汇编:汇编过程实际上指把汇编语言代码翻译成目标机器指令的过程。
链接:将有关的目标文件彼此相连接，使得所有的这些目标文件成为一个能够诶操作系统装入执行的统一整体。

8.动态链接库和静态链接库的区别
静态链接库与动态链接库都是共享代码的方式，静态链接库lib 中的指令被直接包含在最终生成的 EXE 文件中。DLL 不必被包含在最终 EXE 文件中，EXE 文件执行时可以“动态”地引用和卸载DLL 文件。静态链接库中不能再包含其他的动态链接库或者静态库，而在动态链接库中还可以再包含其他的动态或静态链接库。
静态lib将导出声明和实现都放在lib中。编译后所有代码都嵌入到宿主程序；动态lib相当于一个h文件，是对实现部分（.dll文件）的导出部分的声明。编译后只是将导出声明部分编译到宿主程序中，运行时候需要相应的dll文件支持
库文件是编译后的二进制代码，不能看到其源代码，链接的时候将lib链接到目标代码中

9. 链接的过程
链接就是将不同部分的代码和数据收集和组合成为一个单一文件的过程,这个文件可被加载或拷贝到存储器执行.
  链接可以执行与编译时(源代码被翻译成机器代码时),也可以执行与加载时(在程序被加载器加载到存储器并执行时),甚至执行与运行时,由应用程序来执行.在现代系统中,链接是由链接器自动执行的.链接主要解决模块间的相互引用问题，分为地址和空间分配，符号解析和重定位几个步骤。
  链接器分为:静态链接器和动态链接器两种.

10.系统调用和库函数比较
由操作系统提供的供应用程序调用的接口。
系统调用和普通调用的区别：运行状态不同。系统调用的调用过程和被调用过程运行在不同的状态，而普通的过程调用一般运行在相同的状态；调用方法不同。系统调用必须通过软中断机制首先进入系统核心，然后才能转向相应的命令处理程序。普通过程调用可以直接由调用过程转向被调用过程；返回问题。在采用抢先式调度的系统中，当系统调用返回时，要重新进行调度分析――是否有更高优先级的任务就绪。普通的过程调用直接返回调用过程继续执行。
函数库中的某些函数调用了系统调用。函数库中的函数可以没有调用系统调用，也可以调用多个系统调用。编程人员可以通过函数库调用系统调用。
 
库函数提供了抽象，可以让我们把更多的注意力集中在要解决问题的核心。
库函数给我们提供的接口更人性化，所以调用起来更方便，可移植性强。
调用库函数更安全，内存管理不用自己太操心。
调用库函数效率更高，程序跑的更快。虽然库函数最终是调用系统函数，但是库函数会比我们用更好的方式方法调用系统函数，比如缓冲机制。

11.fread和操作系统读函数read的区别（库函数、系统调用）
Read 系统调用,fread库函数
库函数更具有可移植性，fopen系列是级别较高的I/O，读写时使用缓冲；而open系列相对低层，更接近操作系统，读写时没有缓冲。
fopen在用户态下有缓存，在进行read和write的时候减少了用户态和内核态的切换，而open则每次都需要进行内核态和用户态的切换； 如果顺序访问文件，fopen系列的函数要比直接调用open系列快；如果随机访问文件open要比 fopen快。

12.动态连接库的两种方式? 调用一个DLL中的函数有两种方法：
1．载入时动态链接（load-time dynamic linking），模块非常明确调用某个导出函数，使得他们就像本地函数一样。这需要链接时链接那些函数所在DLL的导入库，导入库向系统提供了载入DLL时所需的信息及DLL函数定位。
2．运行时动态链接（run-time dynamic linking），运行时可以通过LoadLibrary或LoadLibraryEx函数载入DLL。DLL载入后，模块可以通过调用GetProcAddress获取DLL函数的出口地址，然后就可以通过返回的函数指针调用DLL函数了。如此即可避免导入库文件了。

13.虚拟内存，缺页中断，抖动。
虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存 （一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片， 还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。 与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易， 对真正的物理内存（例如RAM）的使用也更有效率。

缺页中断一个页(Page)是一个固定容量的内存区块，是物理内存和外部存储(如硬盘等) 传输的单位。当一个程序访问一个映射到地址空间却实际并未加载到物理内存的页（page）时， 硬件向软件发出的一次中断（或异常）就是一个缺页中断或叫页错误（page fault）。

抖动（Thrashing）在分页存储管理系统中，内存中只存放了那些经常使用的页面， 而其它页面则存放在外存中，当进程运行需要的内容不在内存时， 便启动磁盘读操作将所需内容调入内存，若内存中没有空闲物理块， 还需要将内存中的某页面置换出去。也就是说，系统需要不断地在内外存之间交换信息。 若在系统运行过程中，刚被淘汰出内存的页面，过后不久又要访问它， 需要再次将其调入。而该页面调入内存后不久又再次被淘汰出内存，然后又要访问它。 如此反复，使得系统把大部分时间用在了页面的调入/换出上， 而几乎不能完成任何有效的工作，这种现象称为抖动。一般是内存分配算法不好，内存太小或者程序的算法不佳引起的页面频繁地从内存调入／调出的行为。

Belady：采用FIFO算法时，如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。Belady现象的原因是FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，即被置换的页面并不是进程不会访问的。这些页在FIFO算法下被反复调入和调出，并且有Belady现象。

14.Linux有内核级线程吗？
线程通常被定义为一个进程中代码的不同执行路线。从实现方式上划分，线程有两种类型：“用户级线程”和“内核级线程”。 用户线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度，和管理线程的函数来控制用户线程。内核级线程需要内核的参与，由内核完成线程的调度。其依赖于操作系统核心，由内核的内部需求进行创建和撤销。
 
用户线程不需要额外的内核开支，并且用户态线程的实现方式可以被定制或修改以适应特殊应用的要求，但是当一个线程因 I/O 而处于等待状态时，整个进程就会被调度程序切换为等待状态，其他线程得不到运行的机会；而内核线程则没有这个个限制，有利于发挥多处理器的并发优势，但却占用了更多的系统开支。

15.信号量、互斥体和自旋锁的区别
信号量/互斥体允许进程睡眠属于睡眠锁，自旋锁则不允许调用者睡眠，而是让其循环等待，所以有以下区别应用 
    1）信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因而自旋锁适合于保持时间非常短的情况
    2）自旋锁可以用于中断，不能用于进程上下文(会引起死锁)。而信号量不允许使用在中断中，而可以用于进程上下文
    3）自旋锁保持期间是抢占失效的，自旋锁被持有时，内核不能被抢占，而信号量和读写信号量保持期间是可以被抢占的

16.进程间的通信如何实现？线程间通信如何实现？
进程间的通信方式
# 管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
# 有名管道 (namedpipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
# 信号量(semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
# 消息队列( messagequeue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
# 信号 (sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
# 共享内存(shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。
# 套接字(socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。



线程间的通信方式

# 锁机制：包括互斥锁、条件变量、读写锁
   *互斥锁提供了以排他方式防止数据结构被并发修改的方法。
   *读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
   *条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
# 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
# 信号机制(Signal)：类似进程间的信号处理
    线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。



17.在Windows编程中互斥量与临界区比较类似，请分析一下二者的主要区别。
两者都可以用于同一进程中不同子线程对资源的互斥访问。临界区是用户模式下的互斥访问手段，互斥量是内核模式下的互斥访问手段。

critical section: 保证在某一时刻只有一个线程能访问数据的简便办法。在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线 程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操 作共享资源的目的。虽然临界区同步速度很快，但却只能用来同步本 进程内的线程，而不可用来同步多个进程中的线程。 

mutex: 互斥量是内核对象，因此还可以用于不同进程中子线程对资源的互斥访问。互斥量可以很好的解决由于线程意外终止资源无法释放的问题。


18.产生死锁的4个必要条件
●　互斥条件：一个资源每次只能被一个进程使用。
●　请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
●　不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
●　循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
3种预防措施：
●　采用资源静态分配策略，破坏“部分分配”条件。
●　允许进程剥夺使用其他进程占有的资源，从而破坏“不可剥夺”条件。
●　采用资源有序分配法，破坏“环路”条件。
这里注意一点：互斥条件无法被破坏。
避免死锁算法中最有代表性的算法是Dijkstra E.W于1968年提出的银行家算法，该算法需要检查申请者对资源的最大需求量，如果系统现存的各类资源可以满足申请者的请求，就满足申请者的请求。这样申请者就可很快完成其计算，然后释放它占用的资源，从而保证了系统中的所有进程都能完成，所以可避免死锁的发生。

19.多线程的实现两种方式
1. 继承 Thread 类
2. 实现 Runnable 接口再 new Thread(YourRunnableOjbect) 

20.多线程同步和互斥有几种实现方法，都是什么？
线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。
用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。

21.多线程同步和互斥有何异同，在什么情况下分别使用他们？举例说明。
线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。

线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步（下文统称为同步）。



22.临界区、互斥量、信号、事件的比较分析。

四种进程或线程同步互斥的控制方法
1、临界区:通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 
2、互斥量:为协调共同对一个共享资源的单独访问而设计的。 
3、信号量:为控制一个具有有限数量用户资源而设计。 
4、事 件:用来通知线程有一些事件已发生，从而启动后继任务的开始。 

critical section: 保证在某一时刻只有一个线程能访问数据的简便办法。在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线 程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操 作共享资源的目的。虽然临界区同步速度很快，但却只能用来同步本 进程内的线程，而不可用来同步多个进程中的线程。 

mutex：互斥量跟临界区很相似，只有拥有互斥对象的线程才具有访问资源的权限，由于互斥对象只有一个，因此就决定了任何情况下此共享资源都不会同时被多个线程 所访问。当前占据资源的线程在任务处理完后应将拥有的互斥对象交出，以便其他线程在获得后得以访问资源。互斥量比临界区复杂。因为使用互斥不仅仅能够在同 一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 

semaphore: 信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程 最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。在用CreateSemaphore（）创建信号量 时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数 就会减1，只要当前可用资源计数是大于0的，就可以发出信号量信号。但是当前可用计数减小到0时则说明当前占用资源的线程数已经达到了所允许的最大数目， 不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离开的同时通过ReleaseSemaphore（）函数将当前可 用资源计数加1。在任何时候当前可用资源计数决不可能大于最大资源计数。 

event: 事件对象也可以通过通知操作的方式来保持线程的同步。并且可以实现不同进程中的线程同步操作。 

1． 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说它可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使 用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。 
2． 互斥量（Mutex），信号灯（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作，而其他的对象与数据同步操作无关，但 对于进程和线程来讲，如果进程和线程在运行状态则为无信号状态，在退出后为有信号状态。所以可以使用WaitForSingleObject来等待进程和 线程退出。 
3． 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根 据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号灯对象可以说是一种资源计数 器。



23._beginthreadex()函数与CreateThread()函数的区别

_beginthreadex()函数在创建新线程时会分配并初始化一个数据块来存放一些需要线程独享的数据。新线程调用标准C运行库函数如strtok()时就会先取得_tiddata块的地址再将需要保护的数据存入_tiddata块中。这样每个线程就只会访问和修改自己的数据而不会去篡改其它线程的数据了。因此，如果在代码中有使用标准C运行库中的函数时，尽量使用_beginthreadex()来代替CreateThread()


24.多线程和单线程各自分别在什么时候效率更高?
多线程在并发，并且各线程无需访问共享数据情况效率高
如果多线程过于频繁切换，或共享数据很多情况下，使用单线程较好

25.在程序设计中，对公共资源(比如缓冲区等)的操作和访问经常需要使用锁来进行保护，但在大并发系统中过多的锁会导致效率很低，通常有那些方法可以尽量避免或减少锁的使用?
减少锁的粒度，每次尽可能减少锁范围
采用队列处理，这样无需使用锁.

26.请详细阐述如何在release版本(windows程序或linux程序都可以)中，查找段错误问题.
可以用编译器生成map文件来定位源码.通过地址反查源码

27.假设你编译链接release版本后得到一个可执行程序(由多个cpp文件和H文件编译)，结果可执行程序文件非常大，你如何找到造成文件太大的可能原因，可能的原因是什么?
使用一个已经初始化的大的全局数组
编译器编译选项、优化选项
静态库
inline
template

28.全局变量

int v = x;

只要x不为0， v就会在.data段里占据4字节空间， 内容是x。x等于0， 或者没有赋初始值； v就不在.data段， 而是.bss段。.bss段的内容在文件映像中不实际存在， 文件映像中只保留它的总大小。

 

29.局部变量

初始化工作需要一些指令去完成， 会增加.text段的大小。

 

30.虚拟地址 (virtual address): CPU启动保护模式后，程序运行在虚拟地址空间中。注意，并不是所有的“程序”都是运行在虚拟地址中。CPU在启动的时候是运行在实模式的，Bootloader以及内核在初始化页表启动的时候是运行在实模式的，Bootloader以及内核在初始化页表之前并不使用虚拟地址，而是直接使用物理地址的。每个进程都有自己的4G地址空间，从0x00000000-0xFFFFFFFF 。通过每个进程自己的一套页目录和页表来实现。由于每个进程有自己的页目录和页表，所以每个进程的地址空间映射的物理内存是不一样的。两个进程的同一个虚拟地址处（如果都有物理内存映射）的值一般是不同的，因为他们往往对应不同的物理页。在windows下4G地址空间中低2G，0x00000000-0x7FFFFFFF 是用户地址空间，4G地址空间中高2G，0x80000000-0xFFFFFFFF是系统地址空间。访问系统地址空间需要程序有ring0的权限。而Linux对4G空间的划分不同与windows。linux将最高的1G 字节（从虚拟地址0xC0000000 到0xFFFFFFFF），供内核使用，称为“内核空间”。而将较低的3G 字节（从虚拟地址0x00000000 到0xBFFFFFFF），供各个进程使用，称为“用户空间”



31.抢占式操作系统的缺点，如何改善
低优先级永远无法执行，长时间不执行的低优先级把优先级调高

32.为什么进程调度比线程调度更消耗cpu
线程共享同一个进程地址空间，线程切换需要保存的上下文以及恢复现场所做的工作要少很多。
多线程共用程序段，不需要进行程序的各种装载，进程调度需要装载各种程序段

33.进程栈和线程栈的区别
线程并没有独立的地址空间，这就意味着隶属同一进程的所有线程栈，都在所属进程的地址空间中，他们的栈地址不同，但是如果操作栈时发生越界，是有可能破坏其他线程的栈空间的。

34.伙伴算法
假设系统的可利用内存空间容量为2m个字(地址从0到2m-1)，则在开始运行时，整个内存区是一个大小为2m的空闲块，在运行了一段时间之后，被分隔成若干占用块和空闲块。为了在分配时查找方便起见，我们将所有大小相同的空闲块建于一张子表中。每个子表是一个双重链表，这样的链表可能有m+1个，将这m+1个表头指针用向量结构组织成一个表，这就是伙伴系统中的可利用空间表，如图所示：

<img src="images/os_4.jpg" alt="jvm物理结构" />

分配算法： 
       当用户提出大小为n的内存请求时，首先在可利用表上寻找结点大小与n相匹配的子表，若此子表非空，则将子表中任意一个结点分配之即可；若此子表为空，则需从结点更大的非空子表中去查找，直至找到一个空闲块，则将其中一部分分配给用户，而将剩余部分插入相应的子表中。若2k-1 < n ≤ 2k-1，又第k+1个子表不空，则只要删除此链表中第一个结点并分配给用户即可；若 2k-2 < n ≤ 2k-1-1，此时由于结点大小为2k-1 的子表为空，则需从结点大小为2k 的子表中取出一块，将其中一半分配给用户，剩余的一半作为一个新结点插入在结点大小为2k-1的子表中，若2k-i-1 < n ≤ 2k-i-1(i为小于是的整数)，并且所有结点小于2k的子表均为空，则同样需从结点大小为2k的子表中取出一块，将其中2k-i的一小部分分配给用户，剩余部分分割成若干个结点分别插入在结点大小为2k-1 、 2k-2 、…、 2k-i的子表中。
回收算法：
       在用户释放不再使用的占用块时，系统需将这新的空闲块插入到可利用空间表中去。这里，同样有一个地址相邻的空闲块归并成大块的问题。但是在伙伴系统中仅考虑互为“伙伴”的两个空闲块的归并。
        何谓“伙伴”?如前所述，在分配时经常需要将一个大的空闲块分裂成两个大小相等的存储区，这两个由同一大块分裂出来的小块就称之“互为伙伴”。例如：假设p为大小为pow(2,k)的空闲块的初始地址，且p MOD pow(2,k+1)=0，则初始地址为p和p+pow(2,k)的两个空闲块互为伙伴。在伙伴系统中回收空闲块时，只当其伙伴为空闲块时才归并成大块。也就是说，若有两个空闲块，即使大小相同且地址相邻，但不是由同一大块分裂出来的，也不归并在一起。由此，在回收空闲块时，应首先判别其伙伴是否为空闲块，若否，则只要将释放的空闲块简单插入在相应子表中即可；若是，则需在相应子表中找到其伙伴并删除之，然后再判别合并后的空闲块的伙伴是否是空闲块。依此重复，直到归并所得空闲块的伙伴不是空闲块时，再插入到相应的子表中去。

35.内存池的主要作用：
一个是 避免全局内存分配操作引发的竞争导致效率低下 [一般多线程进程同时申请系统内存就会引发这个问题]，另一个是 避免内存碎片 [频繁分配释放会导致内存碎片]，并不是考虑操作能够比直接NEW 或者MALLOC来得快 ，内存池的特点就是用于频繁分配释放的小内存。几百M的动态内存是直接映射到共享空间的，不适合从内存池分配。
（1）针对特殊情况，例如需要频繁分配释放固定大小的内存对象时，不需要复杂的分配算法和多线程保护。也不需要维护内存空闲表的额外开销，从而获得较高的性能。
（2）由于开辟一定数量的连续内存空间作为内存池块，因而一定程度上提高了程序局部性，提升了程序性能。
（3）比较容易控制页边界对齐和内存字节对齐，没有内存碎片的问题。
（4）当需要分配管理的内存在100M一下的时候，采用内存池会节省大量的时间，否则会耗费更多的时间。
（5）内存池可以防止更多的内存碎片的产生
（6）更方便于管理内存 

36.select、poll、epoll之间的区别
 select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

select的几大缺点：

（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大

（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大

（3）select支持的文件描述符数量太小了，默认是1024

poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。

epoll是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。

　　对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。

　　对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。

　　对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。



37.高性能游戏服务器需要考虑哪些瓶颈

三次握手队列，数据接受/发送缓冲区等, 考虑大量并发的处理，内存的规划使用，及时处理无效链接，对于高峰和低峰的伸缩处理，适度的缓存等等。



38.多线程应用程序崩溃的原因

随机的变量，比如：用户输入， 程序产生的随机数，当前系统时间等。

内存泄漏

Delete已经释放的内存

程序依赖于其它应用程序或是外部模块

堆栈溢出

多线程读写的数据未加锁保护。

多线程程序使用了线程不安全的函数。

内存访问越界：使用野指针、错误的下标

非法指针 ：使用空指针，随意使用指针转换





39.把文件打开，到最后读出数据，操作系统和硬盘做了哪些工作?

open执行了一次系统调用,获取了文件的描述符，read系统调用从硬盘读取数据到内核缓冲区，然后从内核缓冲区读到用户缓冲区。



40.CPU频率 2.8GHZ   硬盘转速 5400转/分钟



41.进程什么时候会从用户态切换到内核态

（1）系统调用（软中断，内陷到内核，是主动的）

（2）中断（硬件产生，进程被动进入内核态）